{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Multi-organ Segmentation with UNETR (BTCV Challenge)\n",
    "Translated by: **饭饭**.\n",
    "\n",
    "教程修改翻译自 https://github.com/Project-MONAI/tutorials/blob/main/3d_segmentation/unetr_btcv_segmentation_3d_lightning.ipynb\n",
    "\n",
    "本教程展示了MONAI如何与PyTorch Lightning框架结合使用，利用BTCV挑战数据集构建UNETR的多器官分割任务的训练工作流程。\n",
    "\n",
    "![image](https://lh3.googleusercontent.com/pw/AM-JKLU2eTW17rYtCmiZP3WWC-U1HCPOHwLe6pxOfJXwv2W-00aHfsNy7jeGV1dwUq0PXFOtkqasQ2Vyhcu6xkKsPzy3wx7O6yGOTJ7ZzA01S6LSh8szbjNLfpbuGgMe6ClpiS61KGvqu71xXFnNcyvJNFjN=w1448-h496-no?authuser=0)\n",
    "\n",
    "它包含以下流程:\n",
    "1. 字典格式数据的转换。\n",
    "2. 根据MONAI transform API定义一个新的变换。\n",
    "3. 加载Nifti图像通过元数据，加载一系列图像，并将其堆叠。\n",
    "4. 随机调整强度，进行数据增强。\n",
    "5. 缓存IO和转换，以加速训练和验证。\n",
    "6. 三维UNETR模型，Dice损失函数，多器官分割任务的平均Dice度量。\n",
    "\n",
    "数据集来源 https://www.synapse.org/#!Synapse:syn3193805/wiki/217752.  \n",
    "\n",
    "在机构审查委员会（IRB）的监督下，从一个正在进行的结直肠癌化疗试验和一个回顾性的腹腔疝研究中随机选择了50张腹部CT扫描。这50张扫描是在门静脉造影阶段采集的，容积大小（512 x 512 x 85 - 512 x 512 x 198）和视野（大约280 x 280 x 280 mm3 - 500 x 500 x 650 mm3）各不相同。平面内分辨率从0.54 x 0.54 mm2到0.98 x 0.98 mm2不等，而切片厚度从2.5 mm到5.0 mm。\n",
    "\n",
    "目标：13个腹部器官，包括：1. 脾脏 2. 右肾 3. 左肾 4.胆囊 5.食道 6. 肝脏 7. 胃 8.主动脉 9. IVC 10. 门静脉和脾静脉 11. 胰腺 12 右肾上腺 13 左肾上腺。\n",
    "\n",
    "数据类型: CT\n",
    "大小: 30 3D volumes (24 Training + 6 Testing)  \n",
    "挑战: BTCV MICCAI Challenge\n",
    "\n",
    "下图显示了在CT中被注释的器官子区域的图像斑块（左上）和整个数据集的最终标签（右）。\n",
    "\n",
    "数据、图来自于：\n",
    "\n",
    "\n",
    "1. [UNETR: Transformers for 3D Medical Image Segmentation](https://arxiv.org/abs/2103.10504)\n",
    "\n",
    "2. [High-resolution 3D abdominal segmentation with random patch network fusion (MIA)](https://www.sciencedirect.com/science/article/abs/pii/S1361841520302589)\n",
    "\n",
    "3. [Efficient multi-atlas abdominal segmentation on clinically acquired CT with SIMPLE context learning (MIA)](https://www.sciencedirect.com/science/article/abs/pii/S1361841515000766?via%3Dihub)\n",
    "\n",
    "\n",
    "![image](https://lh3.googleusercontent.com/pw/AM-JKLX0svvlMdcrchGAgiWWNkg40lgXYjSHsAAuRc5Frakmz2pWzSzf87JQCRgYpqFR0qAjJWPzMQLc_mmvzNjfF9QWl_1OHZ8j4c9qrbR6zQaDJWaCLArRFh0uPvk97qAa11HtYbD6HpJ-wwTCUsaPcYvM=w1724-h522-no?authuser=0)\n",
    "\n",
    "\n",
    "\n",
    "图像斑块显示了一个主体的解剖结构，包括：\n",
    "1. 大器官：脾、肝、胃。 \n",
    "2. 较小的器官：胆囊、食道、肾脏、胰腺。\n",
    "3. 血管组织：主动脉、IVC、P&S静脉。 \n",
    "4. 腺体：左、右肾上腺\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_segmentation/unetr_btcv_segmentation_3d_lightning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.0.0\n",
      "Numpy version: 1.22.4\n",
      "Pytorch version: 1.11.0+cu113\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 170093375ce29267e45681fcec09dfa856e1d7e7\n",
      "MONAI __file__: d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.18.3\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.12.0+cu113\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.3.2\n",
      "transformers version: 4.12.5\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    RandRotate90d,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNETR\n",
    "\n",
    "from monai.data import (\n",
    "    DataLoader,\n",
    "    CacheDataset,\n",
    "    load_decathlon_datalist,\n",
    "    decollate_batch,\n",
    "    list_data_collate,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.data import ImageDataset, create_test_image_3d, decollate_batch, DataLoader\n",
    "from monai.transforms import Activations, EnsureChannelFirst, AsDiscrete, Compose, RandRotate90, RandSpatialCrop, ScaleIntensity\n",
    "\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = 'tempdataset'\n",
    "if not os.path.exists(tempdir):\n",
    "    os.makedirs(tempdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating synthetic data to tempdataset (this may take a while)\n"
     ]
    }
   ],
   "source": [
    "# create a temporary directory and 40 random image, mask pairs\n",
    "print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=2)\n",
    "\n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"im{i:d}.nii.gz\"))\n",
    "\n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, f\"seg{i:d}.nii.gz\"))\n",
    "\n",
    "images = sorted(glob(os.path.join(tempdir, \"im*.nii.gz\")))\n",
    "segs = sorted(glob(os.path.join(tempdir, \"seg*.nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tempdataset\\\\im0.nii.gz',\n",
       " 'tempdataset\\\\im1.nii.gz',\n",
       " 'tempdataset\\\\im10.nii.gz',\n",
       " 'tempdataset\\\\im11.nii.gz',\n",
       " 'tempdataset\\\\im12.nii.gz',\n",
       " 'tempdataset\\\\im13.nii.gz',\n",
       " 'tempdataset\\\\im14.nii.gz',\n",
       " 'tempdataset\\\\im15.nii.gz',\n",
       " 'tempdataset\\\\im16.nii.gz',\n",
       " 'tempdataset\\\\im17.nii.gz',\n",
       " 'tempdataset\\\\im18.nii.gz',\n",
       " 'tempdataset\\\\im19.nii.gz',\n",
       " 'tempdataset\\\\im2.nii.gz',\n",
       " 'tempdataset\\\\im20.nii.gz',\n",
       " 'tempdataset\\\\im21.nii.gz',\n",
       " 'tempdataset\\\\im22.nii.gz',\n",
       " 'tempdataset\\\\im23.nii.gz',\n",
       " 'tempdataset\\\\im24.nii.gz',\n",
       " 'tempdataset\\\\im25.nii.gz',\n",
       " 'tempdataset\\\\im26.nii.gz',\n",
       " 'tempdataset\\\\im27.nii.gz',\n",
       " 'tempdataset\\\\im28.nii.gz',\n",
       " 'tempdataset\\\\im29.nii.gz',\n",
       " 'tempdataset\\\\im3.nii.gz',\n",
       " 'tempdataset\\\\im30.nii.gz',\n",
       " 'tempdataset\\\\im31.nii.gz',\n",
       " 'tempdataset\\\\im32.nii.gz',\n",
       " 'tempdataset\\\\im33.nii.gz',\n",
       " 'tempdataset\\\\im34.nii.gz',\n",
       " 'tempdataset\\\\im35.nii.gz',\n",
       " 'tempdataset\\\\im36.nii.gz',\n",
       " 'tempdataset\\\\im37.nii.gz',\n",
       " 'tempdataset\\\\im38.nii.gz',\n",
       " 'tempdataset\\\\im39.nii.gz',\n",
       " 'tempdataset\\\\im4.nii.gz',\n",
       " 'tempdataset\\\\im5.nii.gz',\n",
       " 'tempdataset\\\\im6.nii.gz',\n",
       " 'tempdataset\\\\im7.nii.gz',\n",
       " 'tempdataset\\\\im8.nii.gz',\n",
       " 'tempdataset\\\\im9.nii.gz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tempdataset\\\\seg0.nii.gz',\n",
       " 'tempdataset\\\\seg1.nii.gz',\n",
       " 'tempdataset\\\\seg10.nii.gz',\n",
       " 'tempdataset\\\\seg11.nii.gz',\n",
       " 'tempdataset\\\\seg12.nii.gz',\n",
       " 'tempdataset\\\\seg13.nii.gz',\n",
       " 'tempdataset\\\\seg14.nii.gz',\n",
       " 'tempdataset\\\\seg15.nii.gz',\n",
       " 'tempdataset\\\\seg16.nii.gz',\n",
       " 'tempdataset\\\\seg17.nii.gz',\n",
       " 'tempdataset\\\\seg18.nii.gz',\n",
       " 'tempdataset\\\\seg19.nii.gz',\n",
       " 'tempdataset\\\\seg2.nii.gz',\n",
       " 'tempdataset\\\\seg20.nii.gz',\n",
       " 'tempdataset\\\\seg21.nii.gz',\n",
       " 'tempdataset\\\\seg22.nii.gz',\n",
       " 'tempdataset\\\\seg23.nii.gz',\n",
       " 'tempdataset\\\\seg24.nii.gz',\n",
       " 'tempdataset\\\\seg25.nii.gz',\n",
       " 'tempdataset\\\\seg26.nii.gz',\n",
       " 'tempdataset\\\\seg27.nii.gz',\n",
       " 'tempdataset\\\\seg28.nii.gz',\n",
       " 'tempdataset\\\\seg29.nii.gz',\n",
       " 'tempdataset\\\\seg3.nii.gz',\n",
       " 'tempdataset\\\\seg30.nii.gz',\n",
       " 'tempdataset\\\\seg31.nii.gz',\n",
       " 'tempdataset\\\\seg32.nii.gz',\n",
       " 'tempdataset\\\\seg33.nii.gz',\n",
       " 'tempdataset\\\\seg34.nii.gz',\n",
       " 'tempdataset\\\\seg35.nii.gz',\n",
       " 'tempdataset\\\\seg36.nii.gz',\n",
       " 'tempdataset\\\\seg37.nii.gz',\n",
       " 'tempdataset\\\\seg38.nii.gz',\n",
       " 'tempdataset\\\\seg39.nii.gz',\n",
       " 'tempdataset\\\\seg4.nii.gz',\n",
       " 'tempdataset\\\\seg5.nii.gz',\n",
       " 'tempdataset\\\\seg6.nii.gz',\n",
       " 'tempdataset\\\\seg7.nii.gz',\n",
       " 'tempdataset\\\\seg8.nii.gz',\n",
       " 'tempdataset\\\\seg9.nii.gz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_imtrans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),\n",
    "        EnsureChannelFirst(),\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "    ]\n",
    ")\n",
    "train_segtrans = Compose(\n",
    "    [\n",
    "        EnsureChannelFirst(),\n",
    "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
    "        RandRotate90(prob=0.5, spatial_axes=(0, 2)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 96, 96, 96) (10, 1, 96, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "# define image dataset, data loader\n",
    "check_ds = ImageDataset(images, segs, transform=train_imtrans, seg_transform=train_segtrans)\n",
    "check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = monai.utils.misc.first(check_loader)\n",
    "print(im.shape, seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
